{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d92f52f6-ae34-451a-b13d-ae94efc00ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenvNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a9861d0-5557-4fc7-866c-576585a38a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa4dee8b-7737-409f-8280-a85309e30c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.3.14-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached SQLAlchemy-2.0.37-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Using cached aiohttp-3.11.11-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.29 (from langchain)\n",
      "  Using cached langchain_core-0.3.29-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.3,>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.2.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy<3,>=1.26.2 (from langchain)\n",
      "  Using cached numpy-2.2.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Using cached pydantic-2.10.5-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached frozenlist-1.5.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.1.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached propcache-0.2.1-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.18.3-cp312-cp312-win_amd64.whl.metadata (71 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.29->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Using cached orjson-3.10.14-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached pydantic_core-2.27.2-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.1.1-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
      "Using cached langchain-0.3.14-py3-none-any.whl (1.0 MB)\n",
      "Using cached aiohttp-3.11.11-cp312-cp312-win_amd64.whl (437 kB)\n",
      "Using cached langchain_core-0.3.29-py3-none-any.whl (411 kB)\n",
      "Using cached langchain_text_splitters-0.3.5-py3-none-any.whl (31 kB)\n",
      "Using cached langsmith-0.2.10-py3-none-any.whl (326 kB)\n",
      "Using cached numpy-2.2.1-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Using cached pydantic-2.10.5-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "Using cached SQLAlchemy-2.0.37-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached frozenlist-1.5.0-cp312-cp312-win_amd64.whl (51 kB)\n",
      "Using cached greenlet-3.1.1-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached multidict-6.1.0-cp312-cp312-win_amd64.whl (28 kB)\n",
      "Using cached orjson-3.10.14-cp312-cp312-win_amd64.whl (133 kB)\n",
      "Using cached propcache-0.2.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Using cached yarl-1.18.3-cp312-cp312-win_amd64.whl (90 kB)\n",
      "Installing collected packages: tenacity, pydantic-core, propcache, orjson, numpy, multidict, jsonpatch, greenlet, frozenlist, annotated-types, aiohappyeyeballs, yarl, SQLAlchemy, pydantic, aiosignal, langsmith, aiohttp, langchain-core, langchain-text-splitters, langchain\n",
      "Successfully installed SQLAlchemy-2.0.37 aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 annotated-types-0.7.0 frozenlist-1.5.0 greenlet-3.1.1 jsonpatch-1.33 langchain-0.3.14 langchain-core-0.3.29 langchain-text-splitters-0.3.5 langsmith-0.2.10 multidict-6.1.0 numpy-2.2.1 orjson-3.10.14 propcache-0.2.1 pydantic-2.10.5 pydantic-core-2.27.2 tenacity-9.0.0 yarl-1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84fc7f1f-2a88-49ac-b6a2-0bd4619daa1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Using cached langchain_openai-0.3.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from langchain-openai) (0.3.29)\n",
      "Collecting openai<2.0.0,>=1.58.1 (from langchain-openai)\n",
      "  Using cached openai-1.59.7-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Using cached tiktoken-0.8.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai) (0.2.10)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai) (2.10.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.8.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.58.1->langchain-openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.58.1->langchain-openai)\n",
      "  Using cached jiter-0.8.2-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.58.1->langchain-openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
      "  Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-openai) (3.10.14)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.29->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.29->langchain-openai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mt\\desktop\\llm_course\\myenv\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.58.1->langchain-openai) (0.4.6)\n",
      "Using cached langchain_openai-0.3.0-py3-none-any.whl (54 kB)\n",
      "Using cached openai-1.59.7-py3-none-any.whl (454 kB)\n",
      "Using cached tiktoken-0.8.0-cp312-cp312-win_amd64.whl (883 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached jiter-0.8.2-cp312-cp312-win_amd64.whl (204 kB)\n",
      "Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, jiter, distro, tiktoken, openai, langchain-openai\n",
      "Successfully installed distro-1.9.0 jiter-0.8.2 langchain-openai-0.3.0 openai-1.59.7 regex-2024.11.6 tiktoken-0.8.0 tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4648dd28-d6da-4c75-9408-454b3ef1b766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llmModel = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1946cdb-e97c-4efb-881e-9d0b544b7742",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llmModel.invoke(\n",
    "    \"Tell me one fun fact about the Kennedy family.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0ae3cfd-320a-48da-839d-049d6434db06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nOne fun fact about the Kennedy family is that they have a history of athletic prowess. John F. Kennedy was a skilled sailor, and his brother Robert F. Kennedy was a competitive runner. Their sister, Eunice Kennedy Shriver, founded the Special Olympics.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5192ad85-194a-407e-8cc8-d9f360626879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "One fun fact about the Kennedy family is that they have a history of athletic prowess. John F. Kennedy was a skilled sailor, and his brother Robert F. Kennedy was a competitive runner. Their sister, Eunice Kennedy Shriver, founded the Special Olympics.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d51f594a-95f0-46e0-a756-5a315fa5aa8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The Kennedy family has a long history of involvement in politics, with 4 family members serving as United States President. They are also known for their love of sailing, with the family owning multiple sailboats and participating in various regattas."
     ]
    }
   ],
   "source": [
    "for chunk in llmModel.stream(\n",
    "    \"Tell me one fun fact about the Kennedy family.\"\n",
    "):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fc0a240-8dc8-4504-9510-102eb23ea34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "creativeLlmModel = OpenAI(temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95b2ad6c-ab89-4c7c-8a20-055130669704",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llmModel.invoke(\n",
    "    \"Write a short 5 line poem about JFK\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e29899f-4781-4309-a7d6-be3ca1632aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A charismatic leader, taken too soon\n",
      "With a vision for peace, he made us swoon\n",
      "His words still echo, his legacy strong\n",
      "In our hearts, his memory will forever belong\n",
      "JFK, a legend, his light still shines on.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d6d4d0a-59c7-4063-b954-f8be603b8a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatModel = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c84954af-421d-4f23-b529-794ee4ca2890",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\"system\", \"You are an historian expert in the Kennedy family.\"),\n",
    "    (\"human\", \"Tell me one curious thing about JFK.\"),\n",
    "]\n",
    "response = chatModel.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a638513c-fed7-4cf9-9046-85b2cd46b680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='One curious fact about John F. Kennedy is that he had a collection of over 1,200 ties and was known for his meticulous attention to his appearance and personal style. Kennedy was a fashion icon of his time, often wearing tailored suits and perfectly knotted ties, which contributed to his image as a charismatic and youthful president.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 67, 'prompt_tokens': 29, 'total_tokens': 96, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-3d0d6ff5-c54f-4ecf-bd3e-db32d4104a45-0', usage_metadata={'input_tokens': 29, 'output_tokens': 67, 'total_tokens': 96, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bb859a0-cfdd-449c-bc30-12432f82af2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One curious fact about John F. Kennedy is that he had a collection of over 1,200 ties and was known for his meticulous attention to his appearance and personal style. Kennedy was a fashion icon of his time, often wearing tailored suits and perfectly knotted ties, which contributed to his image as a charismatic and youthful president.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9929ff9c-b859-4342-a0df-cade8240ea0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 67,\n",
       "  'prompt_tokens': 29,\n",
       "  'total_tokens': 96,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_name': 'gpt-3.5-turbo-0125',\n",
       " 'system_fingerprint': None,\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c58c93d9-ca36-4b42-af3b-dca0790a5379",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mt\\AppData\\Local\\Temp\\ipykernel_10388\\4004604031.py:1: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  response.schema()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'$defs': {'InputTokenDetails': {'description': 'Breakdown of input token counts.\\n\\nDoes *not* need to sum to full input token count. Does *not* need to have all keys.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"audio\": 10,\\n            \"cache_creation\": 200,\\n            \"cache_read\": 100,\\n        }\\n\\n.. versionadded:: 0.3.9',\n",
       "   'properties': {'audio': {'title': 'Audio', 'type': 'integer'},\n",
       "    'cache_creation': {'title': 'Cache Creation', 'type': 'integer'},\n",
       "    'cache_read': {'title': 'Cache Read', 'type': 'integer'}},\n",
       "   'title': 'InputTokenDetails',\n",
       "   'type': 'object'},\n",
       "  'InvalidToolCall': {'description': 'Allowance for errors made by LLM.\\n\\nHere we add an `error` key to surface errors made during generation\\n(e.g., invalid JSON arguments.)',\n",
       "   'properties': {'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'title': 'Name'},\n",
       "    'args': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Args'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "    'error': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "     'title': 'Error'},\n",
       "    'type': {'const': 'invalid_tool_call', 'title': 'Type', 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id', 'error'],\n",
       "   'title': 'InvalidToolCall',\n",
       "   'type': 'object'},\n",
       "  'OutputTokenDetails': {'description': 'Breakdown of output token counts.\\n\\nDoes *not* need to sum to full output token count. Does *not* need to have all keys.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"audio\": 10,\\n            \"reasoning\": 200,\\n        }\\n\\n.. versionadded:: 0.3.9',\n",
       "   'properties': {'audio': {'title': 'Audio', 'type': 'integer'},\n",
       "    'reasoning': {'title': 'Reasoning', 'type': 'integer'}},\n",
       "   'title': 'OutputTokenDetails',\n",
       "   'type': 'object'},\n",
       "  'ToolCall': {'description': 'Represents a request to call a tool.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"name\": \"foo\",\\n            \"args\": {\"a\": 1},\\n            \"id\": \"123\"\\n        }\\n\\n    This represents a request to call the tool named \"foo\" with arguments {\"a\": 1}\\n    and an identifier of \"123\".',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'title': 'Args', 'type': 'object'},\n",
       "    'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Id'},\n",
       "    'type': {'const': 'tool_call', 'title': 'Type', 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id'],\n",
       "   'title': 'ToolCall',\n",
       "   'type': 'object'},\n",
       "  'UsageMetadata': {'description': 'Usage metadata for a message, such as token counts.\\n\\nThis is a standard representation of token usage that is consistent across models.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        {\\n            \"input_tokens\": 350,\\n            \"output_tokens\": 240,\\n            \"total_tokens\": 590,\\n            \"input_token_details\": {\\n                \"audio\": 10,\\n                \"cache_creation\": 200,\\n                \"cache_read\": 100,\\n            },\\n            \"output_token_details\": {\\n                \"audio\": 10,\\n                \"reasoning\": 200,\\n            }\\n        }\\n\\n.. versionchanged:: 0.3.9\\n\\n    Added ``input_token_details`` and ``output_token_details``.',\n",
       "   'properties': {'input_tokens': {'title': 'Input Tokens', 'type': 'integer'},\n",
       "    'output_tokens': {'title': 'Output Tokens', 'type': 'integer'},\n",
       "    'total_tokens': {'title': 'Total Tokens', 'type': 'integer'},\n",
       "    'input_token_details': {'$ref': '#/$defs/InputTokenDetails'},\n",
       "    'output_token_details': {'$ref': '#/$defs/OutputTokenDetails'}},\n",
       "   'required': ['input_tokens', 'output_tokens', 'total_tokens'],\n",
       "   'title': 'UsageMetadata',\n",
       "   'type': 'object'}},\n",
       " 'additionalProperties': True,\n",
       " 'description': 'Message from an AI.\\n\\nAIMessage is returned from a chat model as a response to a prompt.\\n\\nThis message represents the output of the model and consists of both\\nthe raw output as returned by the model together standardized fields\\n(e.g., tool calls, usage metadata) added by the LangChain framework.',\n",
       " 'properties': {'content': {'anyOf': [{'type': 'string'},\n",
       "    {'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]},\n",
       "     'type': 'array'}],\n",
       "   'title': 'Content'},\n",
       "  'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "  'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "  'type': {'const': 'ai', 'default': 'ai', 'title': 'Type', 'type': 'string'},\n",
       "  'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'title': 'Name'},\n",
       "  'id': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'title': 'Id'},\n",
       "  'example': {'default': False, 'title': 'Example', 'type': 'boolean'},\n",
       "  'tool_calls': {'default': [],\n",
       "   'items': {'$ref': '#/$defs/ToolCall'},\n",
       "   'title': 'Tool Calls',\n",
       "   'type': 'array'},\n",
       "  'invalid_tool_calls': {'default': [],\n",
       "   'items': {'$ref': '#/$defs/InvalidToolCall'},\n",
       "   'title': 'Invalid Tool Calls',\n",
       "   'type': 'array'},\n",
       "  'usage_metadata': {'anyOf': [{'$ref': '#/$defs/UsageMetadata'},\n",
       "    {'type': 'null'}],\n",
       "   'default': None}},\n",
       " 'required': ['content'],\n",
       " 'title': 'AIMessage',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fec012e9-8de0-4307-836f-ceea321c3757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ad002d2-fb26-4435-b53a-5b6d4b58b751",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are an historian expert on the Kennedy Family.\"),\n",
    "    HumanMessage(content=\"How many children had Joseph P. Kennedy?\"),\n",
    "]\n",
    "\n",
    "response = chatModel.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f4178fa-86da-4086-8f38-b41b5a5a5706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Joseph P. Kennedy and his wife, Rose Kennedy, had nine children: Joseph Jr., John F. Kennedy, Rosemary, Kathleen, Eunice, Patricia, Robert F. Kennedy, Jean, and Edward \"Ted\" Kennedy.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 30, 'total_tokens': 79, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-004b4f94-6674-4882-95d6-259389858797-0', usage_metadata={'input_tokens': 30, 'output_tokens': 49, 'total_tokens': 79, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "717a96d3-3a67-453a-b699-872413ae39f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joseph P. Kennedy and his wife Rose Kennedy had nine children together. Their children were Joseph Jr., John F. (Jack), Rosemary, Kathleen, Eunice, Patricia, Robert (Bobby), Jean, and Edward (Ted)."
     ]
    }
   ],
   "source": [
    "for chunk in chatModel.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a725b38-0c7a-4cf2-9723-2bd8b14232ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are expert {profession} in {topic}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | chatModel\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"profession\": \"Historian\",\n",
    "        \"topic\": \"Kennedy Family\",\n",
    "        \"input\": \"Tell me one fun fact about JFK.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b783f26-c836-4092-be37-233e25dd5f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='One fun fact about John F. Kennedy is that he won a Pulitzer Prize for his book \"Profiles in Courage\" in 1957. It was a biographical collection of essays about eight U.S. senators who displayed courage in standing up for their beliefs despite facing backlash and criticism.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 28, 'total_tokens': 86, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-423b80f0-4fa1-46bf-b6ec-45d91b350f00-0', usage_metadata={'input_tokens': 28, 'output_tokens': 58, 'total_tokens': 86, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aed844-b176-4902-9f0d-d99f50278ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
